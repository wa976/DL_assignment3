{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"assignment3.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"cells":[{"cell_type":"markdown","metadata":{"id":"6vFXgflvZ6Ga"},"source":["## Assignment #3"]},{"cell_type":"markdown","metadata":{"id":"UevAU0CYVhiu"},"source":["* Release date: 2021/04/26\n","* Due date: **2021/05/09 23:59** (will not accept late submission)\n","* Submittion format: notebook file which can be executed in Colab environment\n","* Weighting: 10% (total 100 pts)"]},{"cell_type":"markdown","metadata":{"id":"FH-S9c5dYgqd"},"source":["* We will train CNN using `dogs_vs_cats_subset.zip` distributed in the class."]},{"cell_type":"markdown","metadata":{"id":"KxrhNNhWbfHD"},"source":["> ### (5pts) Prepare the dataset\n","\n","* Place the unzipped files in some directory on your Colab instance.\n","* Count the number of JPEG files in `train`, `validation`, and `test` folders."]},{"cell_type":"code","metadata":{"id":"NmLRa5GNeSOi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620568971852,"user_tz":-540,"elapsed":2031,"user":{"displayName":"정승규","photoUrl":"","userId":"09485961021551940043"}},"outputId":"2bdb59b0-f64f-46a2-da48-fdc9babea2aa"},"source":["# mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","# unzip\n","import zipfile, os, shutil\n","\n","dataset = '/content/gdrive/My Drive/deeplearning/dogs_vs_cats_subset.zip'\n","dst_path = '/content/dogs_vs_cats_subset'\n","dst_file = os.path.join(dst_path, 'dogs_vs_cats_subset.zip')\n","\n","if not os.path.exists(dst_path):\n","  os.makedirs(dst_path)\n","\n","# copy zip file\n","shutil.copy(dataset, dst_file)\n","  \n","with zipfile.ZipFile(dst_file, 'r') as file:\n","  file.extractall(dst_path)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Jjy4EGMpqUP1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620568971854,"user_tz":-540,"elapsed":2022,"user":{"displayName":"정승규","photoUrl":"","userId":"09485961021551940043"}},"outputId":"15a9ba72-9549-4349-db98-ce748d394574"},"source":["train_cats_dir = os.path.join(dst_path, 'subset/train/cats')\n","train_dogs_dir = os.path.join(dst_path, 'subset/train/dogs')\n","\n","validation_cats_dir = os.path.join(dst_path, 'subset/validation/cats')\n","validation_dogs_dir = os.path.join(dst_path, 'subset/validation/dogs')\n","\n","test_cats_dir = os.path.join(dst_path, 'subset/test/cats')\n","test_dogs_dir = os.path.join(dst_path, 'subset/test/dogs')\n","\n","print('total training cat images:', len(os.listdir(train_cats_dir)))\n","print('total training dog images:', len(os.listdir(train_dogs_dir)))\n","\n","print('total validation cat images:', len(os.listdir(validation_cats_dir)))\n","print('total validation dog images:', len(os.listdir(validation_dogs_dir)))\n","\n","print('total test cat images:', len(os.listdir(test_cats_dir)))\n","print('total test dog images:', len(os.listdir(test_dogs_dir)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["total training cat images: 1000\n","total training dog images: 1000\n","total validation cat images: 500\n","total validation dog images: 500\n","total test cat images: 500\n","total test dog images: 500\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yWfgUJiPeicE"},"source":["> ### (20pts) Build a baseline model\n","\n","* **(10pts)** Use VGG16 model as a baseline model.\n","  * You can use `tensorflow.keras.applications` module to get the VGG16 architecture.\n","  * You should customize the VGG16 model to deal with a given task, i.e., two class classification.\n","  * We will use 128*128 resized images as inputs to the model and randomly initialized model parameters.\n","  * Place **two output nodes** at the output layer.\n","  * Others not specified should be chosen yourself."]},{"cell_type":"code","metadata":{"id":"q9iKnDBqKKGC"},"source":["from tensorflow.keras.applications import VGG16\n","from tensorflow.keras import models\n","from tensorflow.keras import layers\n","\n","\n","conv_base = VGG16(include_top=False,\n","                  input_shape=(128, 128, 3))\n","\n","conv_base.summary()\n","\n","model = models.Sequential()\n","model.add(conv_base)\n","model.add(layers.Flatten())\n","model.add(layers.Dense(256, activation='relu'))\n","model.add(layers.Dense(2, activation='softmax'))\n","\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"w0sIu0iibFXN"},"source":["* **(10pts)** How many trainable parameters in the first convolutional layer? Explain how to compute the number of parameters."]},{"cell_type":"markdown","metadata":{"id":"AZgC-Hux_-h2"},"source":["첫번째 convolutinal layer를 보게 되면 학습가능한 파라미터의 개수가 1792개 인것을 알 수 있다. 이의 계산은 (input channal=3)X(output channel=64)X(filter size=3)X(filter size=3)+(output channel=64) = 1792 임을 알 수 있다."]},{"cell_type":"markdown","metadata":{"id":"j0TUwiHLgI_-"},"source":["> ### (10pts) Train a baseline model \n","\n","  * Currently, the data is stored as JPEG files. So we need the following steps:\n","    * Read the files.\n","    * Decode the JPEG content to RGB grids of pixels.\n","    * Convert these into floating-point tensors.\n","    * Scaling the data to be in a range of [0,1].\n","    \n","  * Set `batch_size` to 20.\n","  * Train the network for 50 epochs. It may consume some time. Note that you should set `steps_per_epoch` and `validation_steps` properly so that a particular data is processed once during a single epoch.\n","  * **Use Adam optimizer to train the model**. You may need to find hyperparameters (e.g., learning rate) to make the optimizer work.\n","  * Here, you don't need to apply any regularization methods. "]},{"cell_type":"code","metadata":{"id":"g1mIkdGs1wx8"},"source":["from tensorflow.keras import optimizers\n","\n","conv_base.trainable = False\n","\n","\n","model.compile(loss='CategoricalCrossentropy',\n","              optimizer=optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999), \n","              metrics=['acc'])\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0L7QFstoSCi5"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","import os \n","train_dir = os.path.join(dst_path, 'subset/train')\n","validation_dir = os.path.join(dst_path, 'subset/validation')\n","\n","train_datagen = ImageDataGenerator(rescale=1./255)\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","\n","\n","train_generator = train_datagen.flow_from_directory(train_dir,\n","                                                    target_size=(128,128),\n","                                                    batch_size=20,\n","                                                    class_mode='categorical')\n","\n","validation_generator = test_datagen.flow_from_directory(validation_dir,\n","                                                        target_size=(128,128),\n","                                                        batch_size=20,\n","                                                        class_mode='categorical')\n","history = model.fit_generator(train_generator,\n","                              steps_per_epoch=100,\n","                              epochs=50,\n","                              validation_data=validation_generator,\n","                              validation_steps=50)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r9HNF524XkCy"},"source":["> ### (5pts) Plot some curves\n","* Plot accuracies and losses on training and validation datasets, respectively."]},{"cell_type":"code","metadata":{"id":"bhDWsnWuY5w-"},"source":["import matplotlib.pyplot as plt\n","\n","acc = history.history['acc'] \n","val_acc = history.history['val_acc'] \n","loss = history.history['loss'] \n","val_loss = history.history['val_loss']\n","\n","epochs = range(1, len(acc) + 1)\n","\n","plt.plot(epochs, acc, 'bo', label='Training acc') \n","plt.plot(epochs, val_acc, 'b', label='Validation acc') \n","plt.title('Training and validation accuracy') \n","plt.legend()\n","\n","plt.figure()\n","\n","plt.plot(epochs, loss, 'bo', label='Training loss') \n","plt.plot(epochs, val_loss, 'b', label='Validation loss') \n","plt.title('Training and validation loss') \n","plt.legend()\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"grS8nv2u6ImO"},"source":["> ### (50pts) Improve the baseline model\n","* Try at least three strategies to improve the validation performance of the baseline model.\n","* You should examine that the performance is indeed improved as you employ your strategies. In other words, you should show that (accuracy with strategy 1 <= accuracy with strategy 1 and 2 <= accuracy with strategy 1, 2, and 3)."]},{"cell_type":"markdown","metadata":{"id":"i9kMzIjGBDTD"},"source":[">> ### (15pts) Trial 1: something"]},{"cell_type":"markdown","metadata":{"id":"Ljrpwbd4T8Y0"},"source":["input shape를 VGG16의 default값인 224,224로 바꾸어주고 dropout을 추가한다"]},{"cell_type":"code","metadata":{"id":"Z2D37Y11fAFA"},"source":["\n","conv_base_2 = VGG16(include_top=False,\n","                  input_shape=(224, 224, 3))\n","\n","model_2 = models.Sequential()\n","model_2.add(conv_base_2)\n","model_2.add(layers.Flatten())\n","model_2.add(layers.Dense(256, activation='relu'))\n","model_2.add(layers.Dropout(0.5))\n","model_2.add(layers.Dense(2, activation='softmax'))\n","\n","conv_base_2.trainable = False\n","\n","\n","model_2.compile(loss='CategoricalCrossentropy',\n","              optimizer=optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999), \n","              metrics=['acc'])\n","\n","train_generator = train_datagen.flow_from_directory(train_dir,\n","                                                    target_size=(224,224),\n","                                                    batch_size=20,\n","                                                    class_mode='categorical')\n","\n","validation_generator = test_datagen.flow_from_directory(validation_dir,\n","                                                        target_size=(224,224),\n","                                                        batch_size=20,\n","                                                        class_mode='categorical')\n","history = model_2.fit_generator(train_generator,\n","                              steps_per_epoch=100,\n","                              epochs=50,\n","                              validation_data=validation_generator,\n","                              validation_steps=50)\n","\n","acc = history.history['acc'] \n","val_acc = history.history['val_acc'] \n","loss = history.history['loss'] \n","val_loss = history.history['val_loss']\n","\n","epochs = range(1, len(acc) + 1)\n","\n","plt.plot(epochs, acc, 'bo', label='Training acc') \n","plt.plot(epochs, val_acc, 'b', label='Validation acc') \n","plt.title('Training and validation accuracy') \n","plt.legend()\n","\n","plt.figure()\n","\n","plt.plot(epochs, loss, 'bo', label='Training loss') \n","plt.plot(epochs, val_loss, 'b', label='Validation loss') \n","plt.title('Training and validation loss') \n","plt.legend()\n","\n","plt.show()\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JwqHqUMTCo-6"},"source":[">> ### (15pts) Trial 2: trial1 + something"]},{"cell_type":"markdown","metadata":{"id":"lC_zTo1cUFxz"},"source":["train data에 여러가지 변화를 주어 train data의 유형과 수를 늘린다."]},{"cell_type":"code","metadata":{"id":"D_V0pniub1rX"},"source":["train_datagen = ImageDataGenerator(rescale=1./255,\n","                                   rotation_range=40,\n","                                   width_shift_range=0.2,\n","                                   height_shift_range=0.2,\n","                                   shear_range=0.2,\n","                                   zoom_range=0.2,\n","                                   horizontal_flip=True,\n","                                   fill_mode='nearest')\n","\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","\n","train_generator = train_datagen.flow_from_directory(train_dir,\n","                                                    target_size=(224,224),\n","                                                    batch_size=20,\n","                                                    class_mode='categorical')\n","\n","validation_generator = test_datagen.flow_from_directory(validation_dir,\n","                                                        target_size=(224,224),\n","                                                        batch_size=20,\n","                                                        class_mode='categorical')\n","\n","history = model_2.fit_generator(train_generator,\n","                              steps_per_epoch=100,\n","                              epochs=50,\n","                              validation_data=validation_generator,\n","                              validation_steps=50)\n","\n","\n","\n","acc = history.history['acc'] \n","val_acc = history.history['val_acc'] \n","loss = history.history['loss'] \n","val_loss = history.history['val_loss']\n","\n","epochs = range(1, len(acc) + 1)\n","\n","plt.plot(epochs, acc, 'bo', label='Training acc') \n","plt.plot(epochs, val_acc, 'b', label='Validation acc') \n","plt.title('Training and validation accuracy') \n","plt.legend()\n","\n","plt.figure()\n","\n","plt.plot(epochs, loss, 'bo', label='Training loss') \n","plt.plot(epochs, val_loss, 'b', label='Validation loss') \n","plt.title('Training and validation loss') \n","plt.legend()\n","\n","plt.show()\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3b-8QejdEzAP"},"source":[">> ### (20pts) Trial 3: trial1 + trial2 + something"]},{"cell_type":"markdown","metadata":{"id":"dF0DzJAUUNWW"},"source":["learning rate를 더 작은 값으로 조정한다."]},{"cell_type":"code","metadata":{"id":"CNtALS0hE9FW"},"source":["model_2.compile(loss='CategoricalCrossentropy',\n","              optimizer=optimizers.Adam(lr=0.00001, beta_1=0.9, beta_2=0.999),  #reduce learning rate\n","              metrics=['acc'])\n","\n","\n","history = model_2.fit_generator(train_generator,\n","                              steps_per_epoch=100,\n","                              epochs=50,\n","                              validation_data=validation_generator,\n","                              validation_steps=50)\n","\n","\n","acc = history.history['acc'] \n","val_acc = history.history['val_acc'] \n","loss = history.history['loss'] \n","val_loss = history.history['val_loss']\n","\n","epochs = range(1, len(acc) + 1)\n","\n","plt.plot(epochs, acc, 'bo', label='Training acc') \n","plt.plot(epochs, val_acc, 'b', label='Validation acc') \n","plt.title('Training and validation accuracy') \n","plt.legend()\n","\n","plt.figure()\n","\n","plt.plot(epochs, loss, 'bo', label='Training loss') \n","plt.plot(epochs, val_loss, 'b', label='Validation loss') \n","plt.title('Training and validation loss') \n","plt.legend()\n","\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RwRxndYYDxMg"},"source":["> ### (10pts) Compare the final performance of your models on the test dataset\n","  * Examine the final performance of the baseline, trial1, trial2, and trial3 models.\n","  * Verify the performance is improved as you apply some regularization methods. If not, discuss why.\n"]},{"cell_type":"code","metadata":{"id":"LP_lfPd0CzBa"},"source":[""],"execution_count":null,"outputs":[]}]}